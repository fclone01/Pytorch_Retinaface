{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "# from data import cfg_mnet, cfg_re50\n",
    "from layers.functions.prior_box import PriorBox\n",
    "from utils.nms.py_cpu_nms import py_cpu_nms\n",
    "import cv2\n",
    "from models.retinaface import RetinaFace\n",
    "from utils.box_utils import decode, decode_landm\n",
    "from utils.timer import Timer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIX_AFTER_MODEL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_keys(model, pretrained_state_dict):\n",
    "    ckpt_keys = set(pretrained_state_dict.keys())\n",
    "    model_keys = set(model.state_dict().keys())\n",
    "    used_pretrained_keys = model_keys & ckpt_keys\n",
    "    unused_pretrained_keys = ckpt_keys - model_keys\n",
    "    missing_keys = model_keys - ckpt_keys\n",
    "    print('Missing keys:{}'.format(len(missing_keys)))\n",
    "    print('Unused checkpoint keys:{}'.format(len(unused_pretrained_keys)))\n",
    "    print('Used keys:{}'.format(len(used_pretrained_keys)))\n",
    "    assert len(used_pretrained_keys) > 0, 'load NONE from pretrained checkpoint'\n",
    "    return True\n",
    "\n",
    "\n",
    "def remove_prefix(state_dict, prefix):\n",
    "    ''' Old style model is stored with all names of parameters sharing common prefix 'module.' '''\n",
    "    print('remove prefix \\'{}\\''.format(prefix))\n",
    "    f = lambda x: x.split(prefix, 1)[-1] if x.startswith(prefix) else x\n",
    "    return {f(key): value for key, value in state_dict.items()}\n",
    "\n",
    "\n",
    "def load_model(model, pretrained_path, load_to_cpu):\n",
    "    print('Loading pretrained model from {}'.format(pretrained_path))\n",
    "    if load_to_cpu:\n",
    "        pretrained_dict = torch.load(pretrained_path, map_location=lambda storage, loc: storage)\n",
    "    else:\n",
    "        device = torch.cuda.current_device()\n",
    "        pretrained_dict = torch.load(pretrained_path, map_location=lambda storage, loc: storage.cuda(device))\n",
    "    if \"state_dict\" in pretrained_dict.keys():\n",
    "        pretrained_dict = remove_prefix(pretrained_dict['state_dict'], 'module.')\n",
    "    else:\n",
    "        pretrained_dict = remove_prefix(pretrained_dict, 'module.')\n",
    "    check_keys(model, pretrained_dict)\n",
    "    model.load_state_dict(pretrained_dict, strict=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumANCHOR  2\n",
      "Loading pretrained model from weights/mobilenet0.25_Final.pth\n",
      "remove prefix 'module.'\n",
      "Missing keys:0\n",
      "Unused checkpoint keys:0\n",
      "Used keys:300\n",
      "Finished loading model!\n",
      "RetinaFace(\n",
      "  (body): IntermediateLayerGetter(\n",
      "    (stage1): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
      "        (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
      "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (stage2): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (stage3): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fpn): FPN(\n",
      "    (output1): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (output2): Sequential(\n",
      "      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (output3): Sequential(\n",
      "      (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (merge1): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (merge2): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (ssh1): SSH(\n",
      "    (conv3X3): Sequential(\n",
      "      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv5X5_1): Sequential(\n",
      "      (0): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (conv5X5_2): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv7X7_2): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (conv7x7_3): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (ssh2): SSH(\n",
      "    (conv3X3): Sequential(\n",
      "      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv5X5_1): Sequential(\n",
      "      (0): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (conv5X5_2): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv7X7_2): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (conv7x7_3): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (ssh3): SSH(\n",
      "    (conv3X3): Sequential(\n",
      "      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv5X5_1): Sequential(\n",
      "      (0): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (conv5X5_2): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv7X7_2): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (conv7x7_3): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (ClassHead): ModuleList(\n",
      "    (0-2): 3 x ClassHead(\n",
      "      (conv1x1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (BboxHead): ModuleList(\n",
      "    (0-2): 3 x BboxHead(\n",
      "      (conv1x1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (LandmarkHead): ModuleList(\n",
      "    (0-2): 3 x LandmarkHead(\n",
      "      (conv1x1): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_312046/1036366865.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrained_dict = torch.load(pretrained_path, map_location=lambda storage, loc: storage)\n"
     ]
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)\n",
    "cfg = {\n",
    "    'name': 'mobilenet0.25',\n",
    "    'min_sizes': [[16, 32], [64, 128], [256, 512]],\n",
    "    'steps': [8, 16, 32],\n",
    "    'variance': [0.1, 0.2],\n",
    "    'clip': False,\n",
    "    'loc_weight': 2.0,\n",
    "    'gpu_train': True,\n",
    "    'batch_size': 32,\n",
    "    'ngpu': 1,\n",
    "    'epoch': 250,\n",
    "    'decay1': 190,\n",
    "    'decay2': 220,\n",
    "    'image_size': 640,\n",
    "    'pretrain': False,\n",
    "    'return_layers': {'stage1': 1, 'stage2': 2, 'stage3': 3},\n",
    "    'in_channel': 32,\n",
    "    'out_channel': 64\n",
    "}\n",
    "\n",
    "# net and model\n",
    "net = RetinaFace(cfg=cfg, phase = 'test')\n",
    "net = load_model(net, \"weights/mobilenet0.25_Final.pth\", True)\n",
    "net.eval()\n",
    "print('Finished loading model!')\n",
    "print(net)\n",
    "cudnn.benchmark = True\n",
    "device = torch.device(\"cpu\" if True else \"cuda\")\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces(img_raw,vis_thres=0.9):\n",
    "    if(type(img_raw)==str):\n",
    "        img_raw = cv2.imread(img_raw, cv2.IMREAD_COLOR)\n",
    "    img = np.float32(img_raw)\n",
    "    im_height, im_width, _ = img.shape\n",
    "    scale = torch.Tensor([img.shape[1], img.shape[0], img.shape[1], img.shape[0]])\n",
    "    img -= (104, 117, 123)\n",
    "    img = img.transpose(2, 0, 1)\n",
    "    img = torch.from_numpy(img).unsqueeze(0)\n",
    "    img = img.to(device)\n",
    "    scale = scale.to(device)\n",
    "    _t = {'forward_pass': Timer(), 'misc': Timer()}\n",
    "    resize = 1\n",
    "\n",
    "    _t['forward_pass'].tic()\n",
    "    loc, conf, landms = net(img)  # forward pass\n",
    "    _t['forward_pass'].toc()\n",
    "    _t['misc'].tic()\n",
    "    priorbox = PriorBox(cfg, image_size=(im_height, im_width))\n",
    "    priors = priorbox.forward()\n",
    "    priors = priors.to(device)\n",
    "    prior_data = priors.data\n",
    "    boxes = decode(loc.data.squeeze(0), prior_data, cfg['variance'])\n",
    "    boxes = boxes * scale / resize\n",
    "    boxes = boxes.cpu().numpy()\n",
    "    scores = conf.squeeze(0).data.cpu().numpy()[:, 1]\n",
    "    landms = decode_landm(landms.data.squeeze(0), prior_data, cfg['variance'])\n",
    "    scale1 = torch.Tensor([img.shape[3], img.shape[2], img.shape[3], img.shape[2],\n",
    "                            img.shape[3], img.shape[2], img.shape[3], img.shape[2],\n",
    "                            img.shape[3], img.shape[2]])\n",
    "    scale1 = scale1.to(device)\n",
    "    landms = landms * scale1 / resize\n",
    "    landms = landms.cpu().numpy()\n",
    "\n",
    "    # ignore low scores\n",
    "    inds = np.where(scores > 0.02)[0]\n",
    "    boxes = boxes[inds]\n",
    "    landms = landms[inds]\n",
    "    scores = scores[inds]\n",
    "\n",
    "    # keep top-K before NMS\n",
    "    # order = scores.argsort()[::-1][:args.top_k]\n",
    "    order = scores.argsort()[::-1]\n",
    "    boxes = boxes[order]\n",
    "    landms = landms[order]\n",
    "    scores = scores[order]\n",
    "\n",
    "    # do NMS\n",
    "    dets = np.hstack((boxes, scores[:, np.newaxis])).astype(np.float32, copy=False)\n",
    "    keep = py_cpu_nms(dets, 0.4)\n",
    "\n",
    "    dets = dets[keep, :]\n",
    "    landms = landms[keep]\n",
    "\n",
    "    # keep top-K faster NMS\n",
    "    # dets = dets[:args.keep_top_k, :]\n",
    "    # landms = landms[:args.keep_top_k, :]\n",
    "\n",
    "    dets = np.concatenate((dets, landms), axis=1)\n",
    "    facess  = []\n",
    "    for b in dets:\n",
    "        if b[4] < vis_thres:\n",
    "            continue\n",
    "        xs = b[4]\n",
    "        b = list(map(int, b))\n",
    "        b.append(xs)\n",
    "        facess.append(b)\n",
    "\n",
    "    return facess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "def find_darkest_point_in_box_center(image, x, y, w, h):\n",
    "    # Đọc ảnh\n",
    "    # image = cv2.imread(image_path)\n",
    "\n",
    "    # Chuyển ảnh sang thang độ xám\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Lấy kích thước ảnh\n",
    "    height, width = gray_image.shape\n",
    "\n",
    "    # Xác định tọa độ của góc trên trái và dưới phải dựa trên tâm (x, y)\n",
    "    x1 = max(0, int(x - w / 2))\n",
    "    y1 = max(0, int(y - h / 2))\n",
    "    x2 = min(width, int(x + w / 2))\n",
    "    y2 = min(height, int(y + h / 2))\n",
    "\n",
    "    # Cắt vùng box ra khỏi ảnh\n",
    "    box = gray_image[y1:y2, x1:x2]\n",
    "\n",
    "    # Tìm tọa độ của điểm tối nhất trong box\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(box)\n",
    "\n",
    "    # Tính lại tọa độ điểm tối nhất dựa trên ảnh gốc\n",
    "    darkest_point = (min_loc[0] + x1, min_loc[1] + y1)\n",
    "\n",
    "    return darkest_point\n",
    "\n",
    "def draw_faces_landmarks(image_path, faces_data, output_image_path=None):\n",
    "    image = cv2.imread(image_path)\n",
    "    for  face_data in faces_data:\n",
    "        x1, y1, x2, y2 =face_data[0:4]\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 2)  # Blue box\n",
    "        # S = abs((x1-x2)*(y2-y1))\n",
    "        # 1/4 1/8\n",
    "\n",
    "        if(FIX_AFTER_MODEL):\n",
    "            face_data[5],face_data[6] = find_darkest_point_in_box_center(image,face_data[5],face_data[6],((x2-x1)/4),((y2-y1))/8)\n",
    "            face_data[7],face_data[8] = find_darkest_point_in_box_center(image,face_data[7],face_data[8],((x2-x1)/4),((y2-y1))/8)\n",
    "        for item in range(5,15,2):\n",
    "            cv2.circle(image, (int(face_data[item]), int(face_data[item+1])), 1, (0, 0, 255), 4)  # Red dots\n",
    "        \n",
    "    # Save the image with bounding boxes and landmarks\n",
    "    if(output_image_path):\n",
    "        cv2.imwrite(output_image_path, image)\n",
    "        print(f\"Image saved to {output_image_path}\")\n",
    "    else:\n",
    "        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')  # Tắt hiển thị trục\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'imread'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc:/Users/four/Downloads/tao-dang-chup-anh-tap-the__31__80f9aa9490ee4d3f838d09a140562638.webp\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# img_raw = cv2.imread(image_path, cv2.IMREAD_COLOR)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m facess \u001b[38;5;241m=\u001b[39m \u001b[43mdetect_faces\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(facess))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(facess)\n",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m, in \u001b[0;36mdetect_faces\u001b[0;34m(img_raw, vis_thres)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetect_faces\u001b[39m(img_raw,vis_thres\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(\u001b[38;5;28mtype\u001b[39m(img_raw)\u001b[38;5;241m==\u001b[39m\u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m         img_raw \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m(img_raw, cv2\u001b[38;5;241m.\u001b[39mIMREAD_COLOR)\n\u001b[1;32m      4\u001b[0m     img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32(img_raw)\n\u001b[1;32m      5\u001b[0m     im_height, im_width, _ \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'imread'"
     ]
    }
   ],
   "source": [
    "image_path = \"c:/Users/four/Downloads/tao-dang-chup-anh-tap-the__31__80f9aa9490ee4d3f838d09a140562638.webp\"\n",
    "# img_raw = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "facess = detect_faces(image_path)\n",
    "print(len(facess))\n",
    "print(facess)\n",
    "draw_faces_landmarks(image_path,facess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'facess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 42\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m rotated_img\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Đường dẫn tới ảnh\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# image_path = 'path_to_your_image.jpg'\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Xoay ảnh 15 độ\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m face \u001b[38;5;241m=\u001b[39m \u001b[43mfacess\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     43\u001b[0m rotated_image \u001b[38;5;241m=\u001b[39m rotate_image(image_path, (calculate_angle([face[\u001b[38;5;241m5\u001b[39m],face[\u001b[38;5;241m6\u001b[39m]],[face[\u001b[38;5;241m7\u001b[39m],face[\u001b[38;5;241m8\u001b[39m]])\u001b[38;5;241m+\u001b[39mcalculate_angle([face[\u001b[38;5;241m11\u001b[39m],face[\u001b[38;5;241m12\u001b[39m]],[face[\u001b[38;5;241m13\u001b[39m],face[\u001b[38;5;241m14\u001b[39m]]))\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Hiển thị ảnh đã xoay (nếu cần)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'facess' is not defined"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def calculate_angle(point1, point2):\n",
    "    print(point1,point2)\n",
    "    # Tính độ dốc (slope)\n",
    "    dy = point2[1] - point1[1]\n",
    "    dx = point2[0] - point1[0]\n",
    "    \n",
    "    # Tránh chia cho 0\n",
    "    if dx == 0:\n",
    "        return 90 if dy > 0 else 270  # 90 độ nếu đi lên, 270 độ nếu đi xuống\n",
    "    \n",
    "    slope = dy / dx\n",
    "    \n",
    "    # Tính góc (tính bằng radian và chuyển sang độ)\n",
    "    angle_rad = math.atan(slope)\n",
    "    angle_deg = math.degrees(angle_rad)\n",
    "    \n",
    "    # # Điều chỉnh góc về miền từ 0 đến 360 độ\n",
    "    # if angle_deg < 0:\n",
    "    #     angle_deg += 360\n",
    "    \n",
    "    return angle_deg\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def rotate_image(image_path, angle):\n",
    "    # Mở ảnh\n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    # Xoay ảnh\n",
    "    rotated_img = img.rotate(angle)\n",
    "    \n",
    "    # Lưu ảnh đã xoay\n",
    "    # rotated_img.save('rotated_image.png',quality=100)\n",
    "    \n",
    "    return rotated_img\n",
    "\n",
    "# Đường dẫn tới ảnh\n",
    "# image_path = 'path_to_your_image.jpg'\n",
    "\n",
    "# Xoay ảnh 15 độ\n",
    "face = facess[0]\n",
    "rotated_image = rotate_image(image_path, (calculate_angle([face[5],face[6]],[face[7],face[8]])+calculate_angle([face[11],face[12]],[face[13],face[14]]))/2)\n",
    "\n",
    "# Hiển thị ảnh đã xoay (nếu cần)\n",
    "rotated_image.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'face' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(calculate_angle([\u001b[43mface\u001b[49m[\u001b[38;5;241m5\u001b[39m],face[\u001b[38;5;241m6\u001b[39m]],[face[\u001b[38;5;241m7\u001b[39m],face[\u001b[38;5;241m8\u001b[39m]]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'face' is not defined"
     ]
    }
   ],
   "source": [
    "print(calculate_angle([face[5],face[6]],[face[7],face[8]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'face' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# rectangle_points = [(face[0], face[1]), (face[0]+face[2], face[1]), (face[0]+face[2], face[1]+face[3]), (face[0],face[1]+face[3])]\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m x1,y1,x2,y2 \u001b[38;5;241m=\u001b[39m \u001b[43mface\u001b[49m[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m4\u001b[39m]\n\u001b[1;32m      3\u001b[0m rectangle_points \u001b[38;5;241m=\u001b[39m[[x1,y1],[x2,y1],[x2,y2],[x1,y2]]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(rectangle_points)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'face' is not defined"
     ]
    }
   ],
   "source": [
    "# rectangle_points = [(face[0], face[1]), (face[0]+face[2], face[1]), (face[0]+face[2], face[1]+face[3]), (face[0],face[1]+face[3])]\n",
    "x1,y1,x2,y2 = face[0:4]\n",
    "rectangle_points =[[x1,y1],[x2,y1],[x2,y2],[x1,y2]]\n",
    "print(rectangle_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def rotate_rectangle(points, angle):\n",
    "    # Tính tọa độ trung tâm\n",
    "    center_x = sum(x for x, y in points) / len(points)\n",
    "    center_y = sum(y for x, y in points) / len(points)\n",
    "\n",
    "    # Chuyển đổi góc từ độ sang radian\n",
    "    radian = math.radians(angle)\n",
    "    \n",
    "    # Ma trận xoay\n",
    "    cos_angle = math.cos(radian)\n",
    "    sin_angle = math.sin(radian)\n",
    "    \n",
    "    rotated_points = []\n",
    "    \n",
    "    for (x, y) in points:\n",
    "        # Di chuyển điểm về gốc tọa độ\n",
    "        x -= center_x\n",
    "        y -= center_y\n",
    "        \n",
    "        # Tính tọa độ mới\n",
    "        x_new = x * cos_angle - y * sin_angle\n",
    "        y_new = x * sin_angle + y * cos_angle\n",
    "        \n",
    "        # Di chuyển điểm trở lại vị trí cũ\n",
    "        x_new += center_x\n",
    "        y_new += center_y\n",
    "        \n",
    "        rotated_points.append((x_new, y_new))\n",
    "    \n",
    "    return rotated_points\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'face' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m angel_ \u001b[38;5;241m=\u001b[39m (calculate_angle([\u001b[43mface\u001b[49m[\u001b[38;5;241m5\u001b[39m],face[\u001b[38;5;241m6\u001b[39m]],[face[\u001b[38;5;241m7\u001b[39m],face[\u001b[38;5;241m8\u001b[39m]])\u001b[38;5;241m+\u001b[39mcalculate_angle([face[\u001b[38;5;241m11\u001b[39m],face[\u001b[38;5;241m12\u001b[39m]],[face[\u001b[38;5;241m13\u001b[39m],face[\u001b[38;5;241m14\u001b[39m]]))\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      5\u001b[0m face \u001b[38;5;241m=\u001b[39m facess[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Tọa độ 4 điểm hình chữ nhật (ví dụ)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'face' is not defined"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "angel_ = (calculate_angle([face[5],face[6]],[face[7],face[8]])+calculate_angle([face[11],face[12]],[face[13],face[14]]))/2\n",
    "\n",
    "face = facess[0]\n",
    "\n",
    "# Tọa độ 4 điểm hình chữ nhật (ví dụ)\n",
    "\n",
    "x1,y1,x2,y2 = face[0:4]\n",
    "rectangle_points =[[x1,y1],[x2,y1],[x2,y2],[x1,y2]]\n",
    "print(rectangle_points)\n",
    "# Góc xoay (độ)\n",
    "angle_of_rotation = angel_\n",
    "\n",
    "# Tính tọa độ mới sau khi xoay\n",
    "new_points = rotate_rectangle(rectangle_points, angle_of_rotation)\n",
    "# print()\n",
    "print(\"Tọa độ mới sau khi xoay:\", new_points)\n",
    "\n",
    "def cut_rotated_rectangle(image_path, points):\n",
    "    # Mở ảnh\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Chuyển đổi danh sách điểm thành mảng NumPy\n",
    "    points = np.array(points, dtype='float32')\n",
    "\n",
    "    # Xác định tọa độ cho hình chữ nhật mới\n",
    "    width = int(max(np.linalg.norm(points[0] - points[1]), np.linalg.norm(points[2] - points[3])))\n",
    "    height = int(max(np.linalg.norm(points[0] - points[3]), np.linalg.norm(points[1] - points[2])))\n",
    "\n",
    "    # Điểm góc cho hình chữ nhật đã cắt\n",
    "    dest_points = np.array([\n",
    "        [0, 0],\n",
    "        [width - 1, 0],\n",
    "        [width - 1, height - 1],\n",
    "        [0, height - 1]\n",
    "    ], dtype='float32')\n",
    "\n",
    "    # Tính ma trận biến đổi\n",
    "    M = cv2.getPerspectiveTransform(points, dest_points)\n",
    "\n",
    "    # Cắt hình\n",
    "    cropped_image = cv2.warpPerspective(image, M, (width, height))\n",
    "\n",
    "    return cropped_image\n",
    "\n",
    "\n",
    "cropped_image = cut_rotated_rectangle(image_path, new_points)\n",
    "plt.imshow(cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB))\n",
    "# cv2.imwrite(\"out.jpg\",cropped_image)\n",
    "plt.axis(False)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'imread'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/four/Downloads/matkinh (1).png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m img\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241m293\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'imread'"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"/home/four/Downloads/matkinh (1).png\")\n",
    "img.shape\n",
    "print(293//2)\n",
    "print(1044//4,1044//4*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'VideoCapture'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 63\u001b[0m\n\u001b[1;32m     60\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Chạy hàm phát hiện từ webcam\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m: detect_from_webcam()\n",
      "Cell \u001b[0;32mIn[15], line 27\u001b[0m, in \u001b[0;36mdetect_from_webcam\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetect_from_webcam\u001b[39m():\n\u001b[0;32m---> 27\u001b[0m     cap \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVideoCapture\u001b[49m(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Mở webcam\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     30\u001b[0m         ret, img_raw \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()  \u001b[38;5;66;03m# Đọc từng khung hình từ webcam\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'VideoCapture'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Các cấu hình cần thiết như 'cfg', 'net', và 'device' cần được định nghĩa từ trước\n",
    "def overlay_glasses(frame, eye_points, glasses_img, glass_eye_points):\n",
    "    # Tính kích thước của kính dựa trên khoảng cách hai mắt\n",
    "    eye_dist = np.linalg.norm(eye_points[1] - eye_points[0])\n",
    "    glass_width = int(1.5 * eye_dist)  # Định kích thước kính\n",
    "    glass_height = int(glasses_img.shape[0] * (glass_width / glasses_img.shape[1]))\n",
    "    \n",
    "    # Resize kính\n",
    "    resized_glasses = cv2.resize(glasses_img, (glass_width, glass_height), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # Tính vị trí đặt kính\n",
    "    glasses_center = np.mean(eye_points, axis=0).astype(int)\n",
    "    top_left = (glasses_center[0] - glass_width // 2, glasses_center[1] - glass_height // 2)\n",
    "    \n",
    "    # Overlay kính lên frame\n",
    "    for i in range(glass_height):\n",
    "        for j in range(glass_width):\n",
    "            y, x = top_left[1] + i, top_left[0] + j\n",
    "            if 0 <= x < frame.shape[1] and 0 <= y < frame.shape[0]:\n",
    "                alpha = resized_glasses[i, j, 3] / 255.0  # Transparency\n",
    "                for c in range(3):  # BGR channels\n",
    "                    frame[y, x, c] = int(alpha * resized_glasses[i, j, c] + (1 - alpha) * frame[y, x, c])\n",
    "\n",
    "    return frame\n",
    "\n",
    "def detect_from_webcam():\n",
    "    cap = cv2.VideoCapture(0)  # Mở webcam\n",
    "\n",
    "    while True:\n",
    "        ret, img_raw = cap.read()  # Đọc từng khung hình từ webcam\n",
    "        if not ret:\n",
    "            break\n",
    "        data_faces = detect_faces(img_raw)\n",
    "        for b in data_faces:\n",
    "            cv2.rectangle(img_raw, (b[0], b[1]), (b[2], b[3]), (0, 0, 255), 2)\n",
    "            cx = b[0]\n",
    "            cy = b[1] + 12\n",
    "            cv2.putText(img_raw, f\"{(int(b[15]*10000))/10000}\", (cx, cy),\n",
    "                        cv2.FONT_HERSHEY_DUPLEX, 0.5, (255, 255, 255))\n",
    "\n",
    "            # Vẽ các landmarks\n",
    "            if(FIX_AFTER_MODEL):\n",
    "                x1, y1, x2, y2 =b[0:4]\n",
    "                b[5],b[6] = find_darkest_point_in_box_center(img_raw,b[5],b[6],((x2-x1)/4),((y2-y1))/8)\n",
    "                b[7],b[8] = find_darkest_point_in_box_center(img_raw,b[7],b[8],((x2-x1)/4),((y2-y1))/8)\n",
    "\n",
    "            cv2.circle(img_raw, (b[5], b[6]), 1, (0, 0, 255), 4)\n",
    "            cv2.circle(img_raw, (b[7], b[8]), 1, (0, 255, 255), 4)\n",
    "            cv2.circle(img_raw, (b[9], b[10]), 1, (255, 0, 255), 4)\n",
    "            cv2.circle(img_raw, (b[11], b[12]), 1, (0, 255, 0), 4)\n",
    "            cv2.circle(img_raw, (b[13], b[14]), 1, (255, 0, 0), 4)\n",
    "\n",
    "        # Hiển thị khung hình\n",
    "        cv2.imshow('Webcam Detection', img_raw)\n",
    "    \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Chạy hàm phát hiện từ webcam\n",
    "if True: detect_from_webcam()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104.4030650891055\n"
     ]
    }
   ],
   "source": [
    "eye_points = np.array([[100, 150], [200, 120]])  # Demo vị trí hai mắt\n",
    "eye_dist = np.linalg.norm(eye_points[1] - eye_points[0])\n",
    "print(eye_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'detect_faces' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m data_faces \u001b[38;5;241m=\u001b[39m \u001b[43mdetect_faces\u001b[49m(img_raw)  \u001b[38;5;66;03m# Giả sử hàm detect_faces đã trả về thông tin các gương mặt\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m data_faces:\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;66;03m# Lấy vị trí mắt của từng gương mặt\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     eye_points \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[b[\u001b[38;5;241m5\u001b[39m], b[\u001b[38;5;241m6\u001b[39m]], [b[\u001b[38;5;241m7\u001b[39m], b[\u001b[38;5;241m8\u001b[39m]]])  \u001b[38;5;66;03m# Demo vị trí hai mắt\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'detect_faces' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Đọc hình ảnh kính (nền trong suốt phải là PNG)\n",
    "glasses_img = cv2.imread(\"/home/four/Downloads/matkinh (1).png\", cv2.IMREAD_UNCHANGED)\n",
    "height_glasses_img, width_glasses_img = glasses_img.shape[:2]\n",
    "new_height = 3 * height_glasses_img\n",
    "expanded_img = np.zeros((new_height, width_glasses_img, 4), dtype=np.uint8)\n",
    "start_y = (new_height - height_glasses_img) // 2\n",
    "expanded_img[start_y:start_y + height_glasses_img, :, :] = glasses_img\n",
    "glasses_img = expanded_img\n",
    "glass_eye_points = np.array([[0.25, 0.4], [0.75, 0.4]])  # normalized\n",
    "width_glasses_img, height_glasses_img = glasses_img.shape[1], glasses_img.shape[0]\n",
    "width_eye_glass = int(0.5 * width_glasses_img)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def overlay_glasses(frame, eye_points, glasses_img, glass_eye_points):\n",
    "    eye_dist = np.linalg.norm(eye_points[1] - eye_points[0])\n",
    "    glass_width = int(glasses_img.shape[1] * (eye_dist / width_eye_glass))\n",
    "    glass_height = int(glasses_img.shape[0] * (glass_width / glasses_img.shape[1]))\n",
    "    resized_glasses = cv2.resize(glasses_img, (glass_width, glass_height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    dx, dy = eye_points[1][0] - eye_points[0][0], eye_points[1][1] - eye_points[0][1]\n",
    "    angle = -np.degrees(np.arctan2(dy, dx))\n",
    "    center = (glass_width // 2, glass_height // 2)\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1)\n",
    "\n",
    "    rotated_glasses = cv2.warpAffine(\n",
    "        resized_glasses, \n",
    "        rotation_matrix, \n",
    "        (glass_width, glass_height), \n",
    "        flags=cv2.INTER_LINEAR, \n",
    "        borderMode=cv2.BORDER_CONSTANT, \n",
    "        borderValue=(0, 0, 0, 0)\n",
    "    )\n",
    "\n",
    "    glasses_center = np.mean(eye_points, axis=0).astype(int)\n",
    "    top_left = (glasses_center[0] - glass_width // 2, glasses_center[1] - glass_height // 2)\n",
    "    x1, y1 = max(0, top_left[0]), max(0, top_left[1])\n",
    "    x2, y2 = min(frame.shape[1], x1 + glass_width), min(frame.shape[0], y1 + glass_height)\n",
    "\n",
    "    overlay = rotated_glasses[:y2 - y1, :x2 - x1]\n",
    "    alpha = overlay[:, :, 3:4] / 255.0\n",
    "\n",
    "    frame[y1:y2, x1:x2] = (\n",
    "        alpha * overlay[:, :, :3] + (1 - alpha) * frame[y1:y2, x1:x2]\n",
    "    ).astype(np.uint8)\n",
    "\n",
    "    return frame\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)  # Mở webcam\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, img_raw = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    data_faces = detect_faces(img_raw)  # Giả sử hàm detect_faces đã trả về thông tin các gương mặt\n",
    "    for b in data_faces:\n",
    "        # Lấy vị trí mắt của từng gương mặt\n",
    "        eye_points = np.array([[b[5], b[6]], [b[7], b[8]]])  # Demo vị trí hai mắt\n",
    "        # Áp dụng overlay kính cho từng gương mặt\n",
    "        img_raw = overlay_glasses(img_raw, eye_points, glasses_img, glass_eye_points)\n",
    "\n",
    "    cv2.imshow('WebCam with Glasses', img_raw)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
