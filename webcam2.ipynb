{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumANCHOR  2\n",
      "Loading pretrained model from weights/mobilenet0.25_Final.pth\n",
      "remove prefix 'module.'\n",
      "Missing keys:0\n",
      "Unused checkpoint keys:0\n",
      "Used keys:300\n",
      "Finished loading model!\n",
      "RetinaFace(\n",
      "  (body): IntermediateLayerGetter(\n",
      "    (stage1): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
      "        (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
      "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (stage2): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (stage3): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fpn): FPN(\n",
      "    (output1): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (output2): Sequential(\n",
      "      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (output3): Sequential(\n",
      "      (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (merge1): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (merge2): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (ssh1): SSH(\n",
      "    (conv3X3): Sequential(\n",
      "      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv5X5_1): Sequential(\n",
      "      (0): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (conv5X5_2): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv7X7_2): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (conv7x7_3): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (ssh2): SSH(\n",
      "    (conv3X3): Sequential(\n",
      "      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv5X5_1): Sequential(\n",
      "      (0): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (conv5X5_2): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv7X7_2): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (conv7x7_3): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (ssh3): SSH(\n",
      "    (conv3X3): Sequential(\n",
      "      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv5X5_1): Sequential(\n",
      "      (0): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (conv5X5_2): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv7X7_2): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (conv7x7_3): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (ClassHead): ModuleList(\n",
      "    (0-2): 3 x ClassHead(\n",
      "      (conv1x1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (BboxHead): ModuleList(\n",
      "    (0-2): 3 x BboxHead(\n",
      "      (conv1x1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (LandmarkHead): ModuleList(\n",
      "    (0-2): 3 x LandmarkHead(\n",
      "      (conv1x1): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15761/3193886059.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrained_dict = torch.load(pretrained_path, map_location=lambda storage, loc: storage)\n",
      "/home/four/Code/PBL6/Pytorch_Retinaface/.venv/lib/python3.10/site-packages/torch/cuda/__init__.py:128: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "# from data import cfg_mnet, cfg_re50\n",
    "from layers.functions.prior_box import PriorBox\n",
    "from utils.nms.py_cpu_nms import py_cpu_nms\n",
    "import cv2\n",
    "from models.retinaface import RetinaFace\n",
    "from utils.box_utils import decode, decode_landm\n",
    "from utils.timer import Timer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "FIX_AFTER_MODEL = False\n",
    "\n",
    "def check_keys(model, pretrained_state_dict):\n",
    "    ckpt_keys = set(pretrained_state_dict.keys())\n",
    "    model_keys = set(model.state_dict().keys())\n",
    "    used_pretrained_keys = model_keys & ckpt_keys\n",
    "    unused_pretrained_keys = ckpt_keys - model_keys\n",
    "    missing_keys = model_keys - ckpt_keys\n",
    "    print('Missing keys:{}'.format(len(missing_keys)))\n",
    "    print('Unused checkpoint keys:{}'.format(len(unused_pretrained_keys)))\n",
    "    print('Used keys:{}'.format(len(used_pretrained_keys)))\n",
    "    assert len(used_pretrained_keys) > 0, 'load NONE from pretrained checkpoint'\n",
    "    return True\n",
    "\n",
    "\n",
    "def remove_prefix(state_dict, prefix):\n",
    "    ''' Old style model is stored with all names of parameters sharing common prefix 'module.' '''\n",
    "    print('remove prefix \\'{}\\''.format(prefix))\n",
    "    f = lambda x: x.split(prefix, 1)[-1] if x.startswith(prefix) else x\n",
    "    return {f(key): value for key, value in state_dict.items()}\n",
    "\n",
    "\n",
    "def load_model(model, pretrained_path, load_to_cpu):\n",
    "    print('Loading pretrained model from {}'.format(pretrained_path))\n",
    "    if load_to_cpu:\n",
    "        pretrained_dict = torch.load(pretrained_path, map_location=lambda storage, loc: storage)\n",
    "    else:\n",
    "        device = torch.cuda.current_device()\n",
    "        pretrained_dict = torch.load(pretrained_path, map_location=lambda storage, loc: storage.cuda(device))\n",
    "    if \"state_dict\" in pretrained_dict.keys():\n",
    "        pretrained_dict = remove_prefix(pretrained_dict['state_dict'], 'module.')\n",
    "    else:\n",
    "        pretrained_dict = remove_prefix(pretrained_dict, 'module.')\n",
    "    check_keys(model, pretrained_dict)\n",
    "    model.load_state_dict(pretrained_dict, strict=False)\n",
    "    return model\n",
    "\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "cfg = {\n",
    "    'name': 'mobilenet0.25',\n",
    "    'min_sizes': [[16, 32], [64, 128], [256, 512]],\n",
    "    'steps': [8, 16, 32],\n",
    "    'variance': [0.1, 0.2],\n",
    "    'clip': False,\n",
    "    'loc_weight': 2.0,\n",
    "    'gpu_train': True,\n",
    "    'batch_size': 32,\n",
    "    'ngpu': 1,\n",
    "    'epoch': 250,\n",
    "    'decay1': 190,\n",
    "    'decay2': 220,\n",
    "    'image_size': 640,\n",
    "    'pretrain': False,\n",
    "    'return_layers': {'stage1': 1, 'stage2': 2, 'stage3': 3},\n",
    "    'in_channel': 32,\n",
    "    'out_channel': 64\n",
    "}\n",
    "\n",
    "# net and model\n",
    "net = RetinaFace(cfg=cfg, phase = 'test')\n",
    "net = load_model(net, \"weights/mobilenet0.25_Final.pth\", True)\n",
    "net.eval()\n",
    "print('Finished loading model!')\n",
    "print(net)\n",
    "cudnn.benchmark = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "net = net.to(device)\n",
    "\n",
    "def detect_faces(img_raw,vis_thres=0.9):\n",
    "    if(type(img_raw)==str):\n",
    "        img_raw = cv2.imread(img_raw, cv2.IMREAD_COLOR)\n",
    "    img = np.float32(img_raw)\n",
    "    im_height, im_width, _ = img.shape\n",
    "    scale = torch.Tensor([img.shape[1], img.shape[0], img.shape[1], img.shape[0]])\n",
    "    img -= (104, 117, 123)\n",
    "    img = img.transpose(2, 0, 1)\n",
    "    img = torch.from_numpy(img).unsqueeze(0)\n",
    "    img = img.to(device)\n",
    "    scale = scale.to(device)\n",
    "    _t = {'forward_pass': Timer(), 'misc': Timer()}\n",
    "    resize = 1\n",
    "\n",
    "    _t['forward_pass'].tic()\n",
    "    loc, conf, landms = net(img)  # forward pass\n",
    "    _t['forward_pass'].toc()\n",
    "    _t['misc'].tic()\n",
    "    priorbox = PriorBox(cfg, image_size=(im_height, im_width))\n",
    "    priors = priorbox.forward()\n",
    "    priors = priors.to(device)\n",
    "    prior_data = priors.data\n",
    "    boxes = decode(loc.data.squeeze(0), prior_data, cfg['variance'])\n",
    "    boxes = boxes * scale / resize\n",
    "    boxes = boxes.cpu().numpy()\n",
    "    scores = conf.squeeze(0).data.cpu().numpy()[:, 1]\n",
    "    landms = decode_landm(landms.data.squeeze(0), prior_data, cfg['variance'])\n",
    "    scale1 = torch.Tensor([img.shape[3], img.shape[2], img.shape[3], img.shape[2],\n",
    "                            img.shape[3], img.shape[2], img.shape[3], img.shape[2],\n",
    "                            img.shape[3], img.shape[2]])\n",
    "    scale1 = scale1.to(device)\n",
    "    landms = landms * scale1 / resize\n",
    "    landms = landms.cpu().numpy()\n",
    "\n",
    "    # ignore low scores\n",
    "    inds = np.where(scores > 0.02)[0]\n",
    "    boxes = boxes[inds]\n",
    "    landms = landms[inds]\n",
    "    scores = scores[inds]\n",
    "\n",
    "    # keep top-K before NMS\n",
    "    # order = scores.argsort()[::-1][:args.top_k]\n",
    "    order = scores.argsort()[::-1]\n",
    "    boxes = boxes[order]\n",
    "    landms = landms[order]\n",
    "    scores = scores[order]\n",
    "\n",
    "    # do NMS\n",
    "    dets = np.hstack((boxes, scores[:, np.newaxis])).astype(np.float32, copy=False)\n",
    "    keep = py_cpu_nms(dets, 0.4)\n",
    "\n",
    "    dets = dets[keep, :]\n",
    "    landms = landms[keep]\n",
    "\n",
    "    # keep top-K faster NMS\n",
    "    # dets = dets[:args.keep_top_k, :]\n",
    "    # landms = landms[:args.keep_top_k, :]\n",
    "\n",
    "    dets = np.concatenate((dets, landms), axis=1)\n",
    "    facess  = []\n",
    "    for b in dets:\n",
    "        if b[4] < vis_thres:\n",
    "            continue\n",
    "        xs = b[4]\n",
    "        b = list(map(int, b))\n",
    "        b.append(xs)\n",
    "        facess.append(b)\n",
    "\n",
    "    return facess\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def rotate_rectangle(points, angle):\n",
    "    # Tính tọa độ trung tâm\n",
    "    center_x = sum(x for x, y in points) / len(points)\n",
    "    center_y = sum(y for x, y in points) / len(points)\n",
    "\n",
    "    # Chuyển đổi góc từ độ sang radian\n",
    "    radian = math.radians(angle)\n",
    "    \n",
    "    # Ma trận xoay\n",
    "    cos_angle = math.cos(radian)\n",
    "    sin_angle = math.sin(radian)\n",
    "    \n",
    "    rotated_points = []\n",
    "    \n",
    "    for (x, y) in points:\n",
    "        # Di chuyển điểm về gốc tọa độ\n",
    "        x -= center_x\n",
    "        y -= center_y\n",
    "        \n",
    "        # Tính tọa độ mới\n",
    "        x_new = x * cos_angle - y * sin_angle\n",
    "        y_new = x * sin_angle + y * cos_angle\n",
    "        \n",
    "        # Di chuyển điểm trở lại vị trí cũ\n",
    "        x_new += center_x\n",
    "        y_new += center_y\n",
    "        \n",
    "        rotated_points.append((x_new, y_new))\n",
    "    \n",
    "    return rotated_points\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def combine_images(glasses_path, reflect_path, output_path=\"combined_image.png\"):\n",
    "    \"\"\"\n",
    "    Gộp hai ảnh với độ trong suốt của ảnh đầu tiên (nếu có kênh alpha).\n",
    "    \n",
    "    Args:\n",
    "        glasses_path (str): Đường dẫn tới ảnh kính (glasses_img).\n",
    "        reflect_path (str): Đường dẫn tới ảnh nền (reflect_img).\n",
    "        output_path (str): Đường dẫn lưu ảnh kết quả (mặc định: \"combined_image.png\").\n",
    "    \n",
    "    Returns:\n",
    "        combined_img (numpy.ndarray): Ảnh đã được gộp.\n",
    "    \"\"\"\n",
    "    # Đọc ảnh với kênh alpha\n",
    "    glasses_img = cv2.imread(glasses_path, cv2.IMREAD_UNCHANGED)\n",
    "    reflect_img = cv2.imread(reflect_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    # Kiểm tra kích thước ảnh và resize nếu cần\n",
    "    if glasses_img.shape[:2] != reflect_img.shape[:2]:\n",
    "        reflect_img = cv2.resize(reflect_img, (glasses_img.shape[1], glasses_img.shape[0]))\n",
    "\n",
    "    # Nếu ảnh reflect_img chỉ có 3 kênh (RGB), thêm kênh alpha\n",
    "    if reflect_img.shape[2] == 3:\n",
    "        reflect_img = cv2.cvtColor(reflect_img, cv2.COLOR_BGR2BGRA)\n",
    "\n",
    "    # Tách kênh alpha của glasses_img\n",
    "    b, g, r, a = cv2.split(glasses_img)\n",
    "\n",
    "    # Tạo ảnh overlay từ glasses_img\n",
    "    overlay = cv2.merge((b, g, r))\n",
    "\n",
    "    # Chuẩn hóa kênh alpha\n",
    "    alpha = a / 255.0\n",
    "\n",
    "    # Áp dụng alpha blending (chỉ trên kênh BGR)\n",
    "    for c in range(3):  # Xử lý từng kênh (B, G, R)\n",
    "        reflect_img[:, :, c] = (reflect_img[:, :, c] * (1 - alpha) + overlay[:, :, c] * alpha).astype(np.uint8)\n",
    "\n",
    "    # Lưu ảnh kết quả\n",
    "    # cv2.imwrite(output_path, reflect_img)\n",
    "\n",
    "    return reflect_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Đọc hình ảnh kính (nền trong suốt phải là PNG)\n",
    "glasses_img = cv2.imread(\"matkinh.png\", cv2.IMREAD_UNCHANGED)\n",
    "reflect_img = cv2.imread(\"reflect.png\", cv2.IMREAD_UNCHANGED)\n",
    "# glasses_img = combine_images(\"matkinh.png\", \"reflect.png\")\n",
    "height_glasses_img, width_glasses_img = glasses_img.shape[:2]\n",
    "new_height = 3 * height_glasses_img\n",
    "expanded_img = np.zeros((new_height, width_glasses_img, 4), dtype=np.uint8)\n",
    "start_y = (new_height - height_glasses_img) // 2\n",
    "expanded_img[start_y:start_y + height_glasses_img, :, :] = glasses_img\n",
    "glasses_img = expanded_img\n",
    "glass_eye_points = np.array([[0.25, 0.45], [0.75, 0.45]])  # normalized\n",
    "width_glasses_img, height_glasses_img = glasses_img.shape[1], glasses_img.shape[0]\n",
    "width_eye_glass = int(0.5 * width_glasses_img)\n",
    "\n",
    "# Hàm thay đổi màu kính\n",
    "def change_glasses_color(glasses_img, color):\n",
    "    # Tách các kênh màu R, G, B và alpha (kênh trong suốt)\n",
    "    b, g, r, a = cv2.split(glasses_img)\n",
    "    \n",
    "    # Áp dụng màu mới cho các kênh R, G, B, giữ nguyên alpha\n",
    "    r = cv2.multiply(r, color[2] / 255)\n",
    "    g = cv2.multiply(g, color[1] / 255)\n",
    "    b = cv2.multiply(b, color[0] / 255)\n",
    "    \n",
    "    # Gộp lại các kênh đã thay đổi và alpha\n",
    "    glasses_with_color = cv2.merge([b.astype(np.uint8), g.astype(np.uint8), r.astype(np.uint8), a])\n",
    "    \n",
    "    return glasses_with_color\n",
    "\n",
    "def overlay_glasses(frame, eye_points, glasses_img, glass_eye_points):\n",
    "    eye_dist = np.linalg.norm(eye_points[1] - eye_points[0])\n",
    "    glass_width = int(glasses_img.shape[1] * (eye_dist / width_eye_glass))\n",
    "    glass_height = int(glasses_img.shape[0] * (glass_width / glasses_img.shape[1]))\n",
    "    resized_glasses = cv2.resize(glasses_img, (glass_width, glass_height), interpolation=cv2.INTER_AREA)\n",
    "    glass_eye_points_actual = (glass_eye_points * [glass_width, glass_height]).astype(int)\n",
    "    dx, dy = eye_points[1][0] - eye_points[0][0], eye_points[1][1] - eye_points[0][1]\n",
    "    angle = -np.degrees(np.arctan2(dy, dx))\n",
    "    center = (glass_width // 2, glass_height // 2)\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1)\n",
    "    rotated_glasses = cv2.warpAffine(\n",
    "        resized_glasses, \n",
    "        rotation_matrix, \n",
    "        (glass_width, glass_height), \n",
    "        flags=cv2.INTER_LINEAR, \n",
    "        borderMode=cv2.BORDER_CONSTANT, \n",
    "        borderValue=(0, 0, 0, 0)\n",
    "    )\n",
    "    glass_eye_points_rotated = cv2.transform(\n",
    "        np.array([glass_eye_points_actual], dtype=np.float32), rotation_matrix\n",
    "    )[0].astype(int)\n",
    "    offset = eye_points - glass_eye_points_rotated\n",
    "    glasses_top_left = np.min(offset, axis=0).astype(int)\n",
    "    x1, y1 = glasses_top_left\n",
    "    x2, y2 = x1 + glass_width, y1 + glass_height\n",
    "    x1, y1 = max(0, x1), max(0, y1)\n",
    "    x2, y2 = min(frame.shape[1], x2), min(frame.shape[0], y2)\n",
    "    overlay = rotated_glasses[:y2 - y1, :x2 - x1]\n",
    "    alpha = overlay[:, :, 3:4] / 255.0\n",
    "    frame[y1:y2, x1:x2] = (\n",
    "        alpha * overlay[:, :, :3] + (1 - alpha) * frame[y1:y2, x1:x2]\n",
    "    ).astype(np.uint8)\n",
    "\n",
    "    return frame\n",
    "\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)  # Mở webcam\n",
    "\n",
    "current_color = (255, 255, 255)  # Màu mặc định là trắng\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, img_raw = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    data_faces = detect_faces(img_raw)  # Giả sử hàm detect_faces đã trả về thông tin các gương mặt\n",
    "    for b in data_faces:\n",
    "        eye_points = np.array([[b[5], b[6]], [b[7], b[8]]])  # Demo vị trí hai mắt\n",
    "        glasses_img_colored = change_glasses_color(glasses_img, current_color)\n",
    "        img_raw = overlay_glasses(img_raw, eye_points, glasses_img_colored, glass_eye_points)\n",
    "    cv2.imshow('WebCam with Glasses', img_raw)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('1'):\n",
    "        current_color = (255, 0, 0) \n",
    "    elif key == ord('2'):\n",
    "        current_color = (0, 255, 0)  \n",
    "    elif key == ord('3'):\n",
    "        current_color = (0, 0, 255)  \n",
    "    elif key == ord('4'):\n",
    "        current_color = (255, 255, 0)  \n",
    "    elif key == ord('5'):\n",
    "        current_color = (0, 255, 255)  \n",
    "    elif key == ord('6'):\n",
    "        current_color = (255, 0, 255)  \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
